geval:
  # === 入力データ設定 ===
  dataset:
    # 評価対象となる合成データのパス（複数指定可）
    input_paths:
      - "data/marc_ja_augmented_zero_shot_run1.jsonl"
      - "data/marc_ja_augmented_few_shot_run1.jsonl"
    # 各レコードの本文が入っている列名
    text_column: "sentence"
    # 元ラベルIDを保持している列名（存在しない場合は省略可）
    label_column: "label"
    # ラベルID→ラベル名の対応表（評価プロンプトでラベル名を参照する際に利用）
    label_names:
      - positive
      - negative

  # === 評価モデル設定 ===
  model:
    # G-Evalで利用する採点モデルの種別（augment.pyと同じくhuggingface/unsloth等を指定可能）
    provider: "huggingface"
    # ロードする基盤モデル名（HF HubのモデルID）
    name: "google/gemma-3-4b-it"
    max_seq_length: 4096
    device_map: "auto"
    # 半精度推論に使うdtype（GPUがBF16対応していない場合はfloat16等に変更）
    quantization: "4bit"
    bnb_4bit_use_double_quant: true
    bnb_4bit_quant_type: "nf4"
    quantization_compute_dtype: bfloat16
    torch_dtype: bfloat16
    tokenizer:
      # FastTokenizerを使うかどうか
      use_fast: true

  # === スコアリング(選択肢・デフォルト閾値) ===
  scoring:
    # 指定が無いプロンプト向けのデフォルト閾値。filter.min_score と重複している場合はfilter側が優先。
    min_score: 3.5
    # スコア候補（回答トークン）ごとの数値と文字列表現を定義。モデルが出力しやすい表記を追加すると安定。
    choices:
      - value: 1
        variants: ["1"]
      - value: 2
        variants: ["2"]
      - value: 3
        variants: ["3"]
      - value: 4
        variants: ["4"]
      - value: 5
        variants: ["5"]

  # === 出力ファイルパス ===
  output:
    # スコア付与結果（全プロンプト分をまとめたレコード）を書き出すテンプレート
    dataset_scores_path_template: "data/geval/{dataset_name}_scores.jsonl"
    # プロンプトごとにレコードを書き出すテンプレート（{prompt_name} が利用可能）
    prompt_scores_path_template: "data/geval/{dataset_name}_{prompt_name}_scores.jsonl"

  # === 観点ごとの評価プロンプト ===
  prompts:
    alignment:
      description: "感情一致の観点から生成レビューを評価"
      system_prompt: ""
      user_prompt_template: |-
        あなたはレビュー評価者です。以下の生成レビューが指定された感情ラベル「{label_name}」にどれだけ一致しているかを5段階で評価してください。
        1は全く一致しない、5は完全に一致することを意味します。

        ―― 評価手順 ――
        Step A: ラベル定義の確認
          - {label_name} が示す感情の方向と強度を確認する（例：positive=満足/称賛、negative=不満/批判）。
        Step B: 根拠表現の抽出
          - 極性を示す語（形容詞/副詞/評価語/否定語/比較表現）を抽出する。
          - 逆極性や但し書き（例：「良いが価格が高い」）の有無を確認する。
        Step C: 一貫性と強度
          - 文章全体で極性が一貫しているか、皮肉/言外の否定がないかを点検する。
          - 極性の明確さ・強度（明確/弱い/混在）を判定する。
        Step D: スコア基準
          - 5: 極性が明確かつ一貫。反証となる要素がほぼない。
          - 4: 概ね一致。軽微な混在や但し書きがある。
          - 3: 賛否が拮抗し、極性が曖昧。
          - 2: 主として不一致だが一部一致点がある。
          - 1: ほぼ全面的に不一致。
        Step E: 出力
          - 理由は出力せず、整数スコアのみを記入する。

        生成レビュー:
        {generated_text}

        評価フォーム（数字のみ）:
        スコア:
    fluency:
      description: "自然さ・流暢さの観点から生成レビューを評価"
      system_prompt: ""
      template_variables:
        reference_text: "reference_text"
      user_prompt_template: |-
        あなたは文章校正の専門家です。以下の生成レビューの自然さと読みやすさを評価し、1(不自然)〜5(非常に自然)の整数スコアのみを出力してください。
        比較のための元レビューが存在する場合は参考にしつつ、生成文単体の品質を評価してください。

        ―― 評価手順 ――
        Step A: 文法・表記
          - 品詞の一致、助詞、時制、誤字脱字、句読点、表記ゆれ、不要な改行/スペースを確認する。
        Step B: 自然さ・可読性
          - 語順、冗長性、重複、レジスタの統一（口語/文語）、文の長さのバランスを評価する。
        Step C: 文章の流れ
          - 接続詞・指示語の整合、段落内の論の運び、主語述語の対応を確認する。
        Step D: スコア基準
          - 5: 文法的に正確で自然。読みやすく違和感がない。
          - 4: 小さな不自然はあるが概ね自然。
          - 3: 目立つぎこちなさや誤りが散見される。
          - 2: 誤りが多く読みづらい。
          - 1: 解読が困難。
        Step E: 出力
          - 理由は出力せず、整数スコアのみを記入する。

        元レビュー:
        {reference_text}

        生成レビュー:
        {generated_text}

        評価フォーム（数字のみ）:
        スコア:
    consistency:
      description: "内容の論理的一貫性・主張の安定性の観点から生成レビューを評価"
      system_prompt: ""
      user_prompt_template: |-
        あなたは論理検証の専門家です。以下の生成レビューについて、主張と理由が矛盾せず、一貫した感情・論旨で書かれているかを評価してください。
        1は矛盾や飛躍が多く一貫性が低い、5は矛盾がなく論理の流れが明確で一貫性が高いことを意味します。

        ―― 評価手順 ――
        Step A: 主張の特定
          - 中心となる主張（満足/不満/中立など）を特定する。
        Step B: 理由の対応関係
          - 提示された理由が主張を適切に支持しているか、論理の飛躍や因果の誤りがないかを確認する。
        Step C: 内的整合性
          - 前後で評価が反転していないか、但し書き・例外との整合、時間/数量/条件の整合性を点検する。
        Step D: スコア基準
          - 5: 主張と根拠が首尾一貫し、矛盾がない。
          - 4: 軽微なゆらぎはあるが全体として整合している。
          - 3: 一部に矛盾や飛躍が見られる。
          - 2: 矛盾が多く、筋が通りにくい。
          - 1: 主要部分が相互に食い違う。
        Step E: 出力
          - 理由は出力せず、整数スコアのみを記入する。

        生成レビュー:
        {generated_text}

        評価フォーム（数字のみ）:
        スコア:
    evidence_diversity:
      description: "判断根拠の多様性（複数の観点・具体例の有無）の観点から生成レビューを評価"
      system_prompt: ""
      user_prompt_template: |-
        あなたはレビュー分析の専門家です。以下の生成レビューが、評価の根拠を複数提示しているか（例：製品の複数側面、具体的事例、比較、使用状況など）を評価してください。
        1は根拠が曖昧・単一で具体性が低い、5は複数の独立した根拠が明確かつ具体的に示されていることを意味します。

        ―― 評価手順 ――
        Step A: 根拠の抽出
          - 性能/デザイン/価格/耐久/サポート等の側面を数え、互いに独立しているかを確認する。
        Step B: 具体性・検証可能性
          - 数値、比較、使用状況、再現性のある描写など、具体的な裏付けの有無を確認する。
        Step C: 冗長・同義反復の整理
          - 言い換えや重複をまとめ、実質的に独立した根拠数を見積もる。
        Step D: スコア基準
          - 5: 独立した具体的根拠が複数（目安3つ以上）明示。
          - 4: 独立した根拠が2つ以上で具体性も十分。
          - 3: 根拠はあるが少数または抽象的。
          - 2: 単一、または曖昧で具体性に乏しい。
          - 1: 実質的な根拠が示されていない。
        Step E: 出力
          - 理由は出力せず、整数スコアのみを記入する。

        生成レビュー:
        {generated_text}

        評価フォーム（数字のみ）:
        スコア:
